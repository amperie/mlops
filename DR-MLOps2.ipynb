{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a69aac3-655d-4ff2-ac49-7ecd1c5a9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pytz\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "from datarobot.mlops.mlops import MLOps\n",
    "from datarobot.mlops.connected.client import MLOpsClient\n",
    "from datarobot.mlops.constants import Constants\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1bb39a-ea5c-4b31-a71a-d88eb0d5fed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the training dataset\n",
    "split_ratio = 0.8\n",
    "prediction_threshold = 0.5\n",
    "\n",
    "dataset_filename = \"datasets/mlops-example-surgical-dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_filename)\n",
    "\n",
    "columns = list(df.columns)\n",
    "arr = df.to_numpy()\n",
    "\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "train_data_len = int(arr.shape[0] * split_ratio)\n",
    "\n",
    "train_data = arr[:train_data_len, :-1]\n",
    "label = arr[:train_data_len, -1]\n",
    "test_data = arr[train_data_len:, :-1]\n",
    "test_df = df[train_data_len:]\n",
    "\n",
    "# train the model\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
    "clf.fit(train_data, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017593a4-33c6-45c5-9a8f-859589d4eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "start_time = time.time()\n",
    "predictions_array = clf.predict_proba(test_data)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780b378-3289-4e5d-92c8-507d84fce690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a model package and create the deployment\n",
    "#Run this only once! Or at least clean up after so you don't end up with a lot of deployments\n",
    "# Create and connect the client\n",
    "endpoint = os.environ['MLOPS_SERVICE_URL']\n",
    "token = os.environ['MLOPS_API_TOKEN']\n",
    "DEPLOYMENT_NAME=\"API Example Classification Deployment\"\n",
    "\n",
    "model_info = {\n",
    "        \"name\": \"API Example Classification\",\n",
    "        \"modelDescription\": {\n",
    "            \"description\": \"API Example binary Classifier\",\n",
    "            \"buildEnvironmentType\":\"Python\",\n",
    "            \"modelName\":\"API Example Classifier\"\n",
    "        },\n",
    "        \"target\": {\n",
    "            \"type\": \"Binary\",\n",
    "            \"name\": \"complication\",\n",
    "            \"predictionThreshold\":\".5\",\n",
    "            \"classNames\":[\"1\",\"0\"]}\n",
    "        }\n",
    "\n",
    "mlops_client = MLOpsClient(endpoint, token)\n",
    "\n",
    "# Add training_data to model configuration\n",
    "dataset_id = mlops_client.upload_dataset(dataset_filename)\n",
    "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
    "\n",
    "# Create the model package\n",
    "model_pkg_id = mlops_client.create_model_package(model_info)\n",
    "model_pkg = mlops_client.get_model_package(model_pkg_id)\n",
    "model_id = model_pkg[\"modelId\"]\n",
    "\n",
    "# Deploy the model package\n",
    "deployment_id = mlops_client.deploy_model_package(model_pkg[\"id\"], DEPLOYMENT_NAME)\n",
    "\n",
    "# Enable data drift tracking\n",
    "mlops_client.update_deployment_settings(deployment_id, target_drift=True,\n",
    "                                                  feature_drift=True)\n",
    "_ = mlops_client.get_deployment_settings(deployment_id)\n",
    "\n",
    "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
    "\n",
    "DEPLOYMENT_ID = deployment_id\n",
    "MODEL_ID = model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbe7963-ab37-4028-bb61-4e0178f41fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLOps code for initializing Reporting library\n",
    "m = MLOps().set_deployment_id(DEPLOYMENT_ID).set_kafka_spooler(topic_name='mlops-agent', \n",
    "                                                               bootstrap_servers='52.137.84.88:9092').init()\n",
    "#m = MLOps().set_filesystem_spooler('//tmp').init()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c019323-7b53-41f8-8a06-4841ff653bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data to report to DR\n",
    "   \n",
    "target_column_name = columns[len(columns) - 1]\n",
    "target_values = []\n",
    "orig_labels = test_df[target_column_name].tolist()\n",
    "# Based on prediction value and the threshold assign correct label to each prediction\n",
    "reporting_predictions = []\n",
    "for index, value in enumerate(predictions_array.tolist()):\n",
    "    if len(value) == 1:\n",
    "        # Random forest classifier from scikit-learn can return a single probability value\n",
    "        # instead of 2 values.  We need to infer the other one before reporting predictions,\n",
    "        # because, 'report_predictions_data' expects probability for each class.\n",
    "        value.append(1 - value[0])\n",
    "    reporting_predictions.append(value)\n",
    "    if value[0] < prediction_threshold:\n",
    "        target_values.append(\"0.0\")\n",
    "    else:\n",
    "        target_values.append(\"1.0\")\n",
    "\n",
    "feature_df = test_df.copy()\n",
    "feature_df[target_column_name] = target_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d33fc4-57e9-42f8-b2ff-febd8bb0302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report data to DataRobot\n",
    "m.report_deployment_stats(predictions_array.shape[0], (end_time - start_time) * 1000)\n",
    "\n",
    "# MLOPS: report test features and predictions and association_ids\n",
    "m.report_predictions_data(\n",
    "    features_df=test_df,\n",
    "    predictions=reporting_predictions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f598e3a-b01c-491a-8de2-2ce2bf673158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutdown MLOps library\n",
    "m.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ecdfa8-d90e-401f-8470-d7ccf385555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a08bf5-819f-48f9-aec8-05ac89cb1a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
